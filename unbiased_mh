# File: coupled_mh_kernel.py
"""
File: coupled_mh_kernel.py

This file implements a coupled Metropolis-Hastings (MH) kernel for unbiased MCMC,
integrating deeply with TensorFlow Probability (TFP) by inheriting from
tfp.mcmc.TransitionKernel. It supports Gaussian proposals and two coupling algorithms:
"maximal" and "maximal_reflection". The kernel also records the meeting time per batch.
A state is a tuple (state1, state2) with each tensor having shape [batch, d].

It is assumed that the coupling algorithms (maximal_coupling and
maximal_reflection_coupling_normal) are provided in the module coupling_algorithms.
"""

import tensorflow as tf
import tensorflow_probability as tfp

from coupling_algorithms import maximal_coupling, maximal_reflection_coupling_normal

tfd = tfp.distributions

class CoupledMetropolisHastingsKernel(tfp.mcmc.TransitionKernel):
    def __init__(self,
                 target_log_prob_fn,
                 proposal_var,
                 coupling_method="maximal",
                 max_iter=10,
                 seed=None,
                 name="CoupledMetropolisHastingsKernel"):
        """
        Initialize the coupled MH kernel.

        Args:
            target_log_prob_fn: Function that takes a state (shape [batch, d])
                                and returns the log target density (shape [batch]).
            proposal_var: Scalar representing the variance of the Gaussian proposal.
            coupling_method: String ("maximal" or "maximal_reflection") to choose the coupling algorithm.
            max_iter: Fixed number of iterations for the "maximal" coupling method.
            seed: Optional seed for randomness.
            name: Name of the kernel.
        """
        self._target_log_prob_fn = target_log_prob_fn
        self._proposal_var = proposal_var
        self._coupling_method = coupling_method
        self._max_iter = max_iter
        self._seed_stream = tfp.util.SeedStream(seed, salt=name)
        self._name = name

    @property
    def is_calibrated(self):
        """MH kernel is calibrated."""
        return True

    def one_step(self, current_state, previous_kernel_results):
        """
        Perform one MH step and update meeting time.

        Args:
            current_state: A tuple (state1, state2) where each tensor has shape [batch, d].
            previous_kernel_results: A dict from the previous iteration; must include "t" (iteration counter)
                                     and "meeting_time" (an int32 tensor of shape [batch]).
        Returns:
            new_state: A tuple (new_state1, new_state2).
            new_kernel_results: A dict with updated kernel results.
        """
        with tf.name_scope(self._name + ".one_step"):
            # Unpack current state
            state1, state2 = current_state
            current_log_prob1 = self._target_log_prob_fn(state1)
            current_log_prob2 = self._target_log_prob_fn(state2)

            # Determine dimension and batch size (assumed static)
            stat_shape = state1.shape.as_list()
            if stat_shape[-1] is None or stat_shape[0] is None:
                raise ValueError("Batch and event dimensions must be statically known.")
            d = stat_shape[-1]
            batch_size = stat_shape[0]

            # Compute proposal standard deviation
            scale = tf.sqrt(tf.cast(self._proposal_var, state1.dtype))
            scale_diag = tf.fill([d], scale)
            proposal_d1 = tfd.MultivariateNormalDiag(loc=state1, scale_diag=scale_diag)
            proposal_d2 = tfd.MultivariateNormalDiag(loc=state2, scale_diag=scale_diag)

            # Generate candidate proposals using the chosen coupling method.
            if self._coupling_method == "maximal":
                candidate1, candidate2 = maximal_coupling(
                    proposal_d1, proposal_d2, batch_shape=(batch_size,), max_iter=self._max_iter)
            elif self._coupling_method == "maximal_reflection":
                # For maximal reflection, build a batch of covariance matrices.
                cov_matrix = tf.eye(d, dtype=state1.dtype) * self._proposal_var
                cov = tf.tile(tf.expand_dims(cov_matrix, axis=0), [batch_size, 1, 1])
                candidate1, candidate2 = maximal_reflection_coupling_normal(state1, state2, cov)
            else:
                raise ValueError("Unknown coupling_method: {}".format(self._coupling_method))

            # Compute candidate log densities.
            candidate_log_prob1 = self._target_log_prob_fn(candidate1)
            candidate_log_prob2 = self._target_log_prob_fn(candidate2)

            # Compute log acceptance ratios (symmetric proposal).
            log_alpha1 = candidate_log_prob1 - current_log_prob1
            log_alpha2 = candidate_log_prob2 - current_log_prob2

            # Determine if the candidate proposals are coupled (approximately equal).
            tol = tf.cast(1e-5, state1.dtype)
            coupled = tf.reduce_all(tf.abs(candidate1 - candidate2) < tol, axis=-1)  # shape [batch]

            # Use common random numbers for coupled cases.
            u_common = tf.random.uniform([batch_size], dtype=state1.dtype, seed=self._seed_stream())
            u1 = tf.where(coupled,
                          u_common,
                          tf.random.uniform([batch_size], dtype=state1.dtype, seed=self._seed_stream()))
            u2 = tf.where(coupled,
                          u_common,
                          tf.random.uniform([batch_size], dtype=state1.dtype, seed=self._seed_stream()))

            # MH acceptance: accept if log(u) < min(0, log_alpha)
            accept1 = tf.math.log(u1) < tf.minimum(0.0, log_alpha1)
            accept2 = tf.math.log(u2) < tf.minimum(0.0, log_alpha2)

            new_state1 = tf.where(tf.expand_dims(accept1, -1), candidate1, state1)
            new_state2 = tf.where(tf.expand_dims(accept2, -1), candidate2, state2)

            # Update iteration counter.
            current_t = previous_kernel_results["t"]
            new_t = current_t + 1

            # Update meeting time: if chains are coupled (for batches not yet met), record meeting time.
            old_meeting_time = previous_kernel_results["meeting_time"]  # shape [batch]
            met_now = tf.reduce_all(tf.abs(new_state1 - new_state2) < tol, axis=1)
            new_meeting_time = tf.where(tf.logical_and(tf.equal(old_meeting_time, -1), met_now),
                                        new_t,
                                        old_meeting_time)

            new_kernel_results = {
                "target_log_prob": (tf.where(accept1, candidate_log_prob1, current_log_prob1),
                                    tf.where(accept2, candidate_log_prob2, current_log_prob2)),
                "accepted": (accept1, accept2),
                "proposals": (candidate1, candidate2),
                "current_log_prob": (current_log_prob1, current_log_prob2),
                "t": new_t,
                "meeting_time": new_meeting_time
            }
            new_state = (new_state1, new_state2)
            return new_state, new_kernel_results

    def bootstrap_results(self, current_state):
        """
        Initialize the kernel results.
        Fields: "t" is the iteration counter and "meeting_time" is set to 0 for coupled chains
        and -1 otherwise.
        """
        state1, state2 = current_state
        current_log_prob1 = self._target_log_prob_fn(state1)
        current_log_prob2 = self._target_log_prob_fn(state2)
        tol = tf.cast(1e-5, state1.dtype)
        met_initial = tf.reduce_all(tf.abs(state1 - state2) < tol, axis=1)
        batch_size = tf.shape(state1)[0]
        meeting_time = tf.where(met_initial,
                                tf.zeros([batch_size], dtype=tf.int32),
                                -tf.ones([batch_size], dtype=tf.int32))
        return {
            "target_log_prob": (current_log_prob1, current_log_prob2),
            "accepted": (tf.zeros(tf.shape(current_log_prob1), dtype=tf.bool),
                         tf.zeros(tf.shape(current_log_prob2), dtype=tf.bool)),
            "proposals": (tf.zeros_like(state1), tf.zeros_like(state2)),
            "current_log_prob": (current_log_prob1, current_log_prob2),
            "t": tf.constant(0, dtype=tf.int32),
            "meeting_time": meeting_time
        }
